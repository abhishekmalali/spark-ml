{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#import scipy as sc\n",
    "import autograd.scipy as sc  # Thinly-wrapped scipy\n",
    "import autograd.numpy as np  # Thinly-wrapped numpy\n",
    "from autograd import grad\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load joke data including features\n",
    "\n",
    "# load data using pandas\n",
    "df = pd.read_csv('../data/ratings.csv', sep=' ', header=None)\n",
    "# uid = user id\n",
    "# jid = joke id\n",
    "df.columns = ['uid', 'jid', 'rating']\n",
    "\n",
    "\n",
    "# Let N be the number of users, M be the number of jokes\n",
    "# use +1 for easier referencing later\n",
    "I = df.uid.max() + 1\n",
    "J = df.jid.max() + 1\n",
    "\n",
    "# for this problem, we do not need uid --> remove column!\n",
    "#df = df[['rating', 'jid']]\n",
    "\n",
    "# import joke features Jf\n",
    "dfJ = pd.read_csv('../data/features.csv', sep=' ', header=None)\n",
    "wrange = ['j'+str(w) for w in range(0, 151)]\n",
    "dfJ.columns = wrange\n",
    "dfJ.head()\n",
    "\n",
    "# convert to numpy matrix Jf\n",
    "Jf = dfJ.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loglikelihood is given as\n",
    "$$ \\mathcal{L}(\\beta \\; \\vert \\; \\mathcal{D}, \\theta) = \\sum_{i=1}^n \\log \\left( F_\\epsilon(\\theta_{Y_i} + X_i^T \\beta) - F_\\epsilon(\\theta_{Y_i-1} + X_i^T\\beta) \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the log-likelihood function\n",
    "# Xrat array consisting of (rating, user, item)\n",
    "# Xfeat array indexable by the item column of Xrat which delivers item features\n",
    "# theta is the parameter vector\n",
    "# theta = (u_1, ..., u_I, v_1, ..., v_J, a_1, ..., a_I, b_1, ..., b_J, g, beta_1, ..., beta_L)\n",
    "# i.e. theta has length (I + J) * K + I + J + 1 + L\n",
    "# with u_i, v_j \\in \\mathbb{R}^K\n",
    "# b stores the buckets for R categories (i.e. we have R-1 elements in b)\n",
    "# i.e. in b we store b_1, b_2, ..., b_{R-1} for R different categories\n",
    "def loglikelihood(theta, Xrat, Xfeat, b, I, J, K, R):\n",
    "    \n",
    "    L = Xfeat.shape[1]\n",
    "    \n",
    "    # first implement the easy latent model using probit...\n",
    "    llsum = 0\n",
    "    for row in xrange(Xrat.shape[0]):\n",
    "        rating = Xrat[row, 0]\n",
    "        i = Xrat[row, 1]\n",
    "        j = Xrat[row, 2]\n",
    "        \n",
    "        # asserts for the indices i, j & rating\n",
    "        assert i < I and i >= 0\n",
    "        assert j < J and j >= 0\n",
    "        assert Xfeat.shape[0] == J\n",
    "        assert rating > 0 and rating <= R\n",
    "        \n",
    "        # the model for the latent variable\n",
    "        u_i = theta[K * i:K*(i+1)]\n",
    "        v_j = theta[(I + j) * K:(I + j + 1) * K]\n",
    "        a_i = theta[(I + J) * K + i]\n",
    "        b_j = theta[(I + J) * K + I + j]\n",
    "        g = theta[(I + J) * K + I + J]\n",
    "        beta = theta[(I + J) * K + I + J + 1:]\n",
    "        \n",
    "        # some asserts for the sizes\n",
    "        assert len(u_i) == K\n",
    "        assert len(v_j) == K\n",
    "        assert len(beta) == L\n",
    "        \n",
    "        # the full model (reduce if necessary)\n",
    "        model = np.dot(u_i, v_j) + np.dot(Xfeat[j, :], beta) + a_i + b_j + g\n",
    "        \n",
    "        # the ordinal regression part\n",
    "        # if rating is 1 or R we have a special case\n",
    "        # another possibility would be to use instead of the ifelse construction\n",
    "        # dummy values like +/- 9999 for infty\n",
    "        # note the additional -1 due to space saving!\n",
    "        if rating == R:\n",
    "            # first summand is one as F(infty) = 0 (mathematically not rigourous, limit is more correct)\n",
    "            llsum += np.log(1 - sc.stats.norm.cdf(b[rating - 2] + model))\n",
    "        elif rating == 1:\n",
    "            # second summand is zero as F(-infty) = 0\n",
    "            llsum += np.log(sc.stats.norm.cdf(b[rating - 1] + model))\n",
    "        else:\n",
    "            llsum += np.log(sc.stats.norm.cdf(b[rating - 1] + model) - sc.stats.norm.cdf(b[rating - 2] + model))\n",
    "    return llsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-137313.91639904646"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the gradient\n",
    "\n",
    "# create sample df\n",
    "dftouse = df[['rating', 'uid', 'jid']].head(20000)\n",
    "\n",
    "# as in the given dataset the indices are 1,...,I and 1, ..., J\n",
    "# adjust jokes & uid s.t. they serve the 0, ..., I-1 and 0, ..., J-1 space \n",
    "dftouse['uid'] = dftouse['uid'] - 1\n",
    "dftouse['jid'] = dftouse['jid'] - 1\n",
    "\n",
    "# transform ratings to range 1, ..., R\n",
    "rating_vals = np.sort(pd.unique(dftouse['rating'].values.ravel()))\n",
    "minR = dftouse.rating.min()\n",
    "dftouse['rating'] = dftouse['rating'] - minR + 1\n",
    "R = len(rating_vals)\n",
    "\n",
    "# create buckets as midpoints\n",
    "buckets = 0.5 * (rating_vals[1:] + rating_vals[:-1])\n",
    "\n",
    "# get length I, J\n",
    "I = dftouse.uid.max() + 1\n",
    "J = dftouse.jid.max() + 1\n",
    "\n",
    "# define some K\n",
    "K = 2\n",
    "\n",
    "# convert to numpy data matrix\n",
    "Xrat = np.array(dftouse)\n",
    "Xfeat = Jf\n",
    "\n",
    "# create dummy theta vector (all zeros)\n",
    "L = Xfeat.shape[1]\n",
    "theta = np.zeros((I + J) * K + I + J + 1 + L)\n",
    "\n",
    "# init theta vector with some random values\n",
    "theta = np.random.normal(size=theta.shape[0], loc=0., scale=0.1)\n",
    "\n",
    "# compute log likelihood\n",
    "loglikelihood(theta, Xrat, Xfeat, buckets, I, J, K, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the rowlikelihood for sgd\n",
    "def rowloglikelihood(theta, row, Xrat, Xfeat, b, I, J, K, R):\n",
    "    L = Xfeat.shape[1]\n",
    "    rating = Xrat[row, 0]\n",
    "    i = Xrat[row, 1]\n",
    "    j = Xrat[row, 2]\n",
    "\n",
    "    # asserts for the indices i, j & rating\n",
    "    assert i < I and i >= 0\n",
    "    assert j < J and j >= 0\n",
    "    assert Xfeat.shape[0] == J\n",
    "    assert rating > 0 and rating <= R\n",
    "\n",
    "    # the model for the latent variable\n",
    "    u_i = theta[K * i:K*(i+1)]\n",
    "    v_j = theta[(I + j) * K:(I + j + 1) * K]\n",
    "    a_i = theta[(I + J) * K + i]\n",
    "    b_j = theta[(I + J) * K + I + j]\n",
    "    g = theta[(I + J) * K + I + J]\n",
    "    beta = theta[(I + J) * K + I + J + 1:]\n",
    "\n",
    "    # some asserts for the sizes\n",
    "    assert len(u_i) == K\n",
    "    assert len(v_j) == K\n",
    "    assert len(beta) == L\n",
    "\n",
    "    # the full model (reduce if necessary)\n",
    "    # model with features does not work yet...\n",
    "    model = np.dot(u_i, v_j)+ a_i + b_j + g# + np.dot(Xfeat[j, :], beta) \n",
    "\n",
    "    # the ordinal regression part\n",
    "    # if rating is 1 or R we have a special case\n",
    "    # another possibility would be to use instead of the ifelse construction\n",
    "    # dummy values like +/- 9999 for infty\n",
    "    # note the additional -1 due to space saving!\n",
    "    if rating == R:\n",
    "        # first summand is one as F(infty) = 0 (mathematically not rigourous, limit is more correct)\n",
    "        return np.log(1 - sc.stats.norm.cdf(b[rating - 2] + model))\n",
    "    elif rating == 1:\n",
    "        # second summand is zero as F(-infty) = 0\n",
    "        return np.log(sc.stats.norm.cdf(b[rating - 1] + model))\n",
    "    else:\n",
    "        return np.log(sc.stats.norm.cdf(b[rating - 1] + model) - sc.stats.norm.cdf(b[rating - 2] + model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use autograd to get a gradient out of the rowlikelihood\n",
    "gradrll = grad(rowloglikelihood)\n",
    "gradll = grad(loglikelihood)\n",
    "\n",
    "# check that gradient has the right length and output sample\n",
    "assert len(gradrll(theta, 5, Xrat, Xfeat, buckets, I, J, K, R)) == (I + J) * K + I + J + 1 + L\n",
    "gradrll(theta, 5, Xrat, Xfeat, buckets, I, J, K, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-143999.50755044774, -137313.91639904646)\n",
      "[ 0.51636719 -0.20649227  0.         ...,  0.          0.          0.        ]\n",
      "[  5.64283628e-01  -2.26692935e-01   0.00000000e+00 ...,  -4.30281282e+03\n",
      "  -5.73342881e+03  -6.01685098e+04]\n",
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# test the row likelihood by comparing to the full one\n",
    "llsum = 0.\n",
    "for row in xrange(Xrat.shape[0]):\n",
    "    llsum += rowloglikelihood(theta, row, Xrat, Xfeat, buckets, I, J, K, R)\n",
    "print (llsum, loglikelihood(theta, Xrat, Xfeat, buckets, I, J, K, R))\n",
    "\n",
    "# do analogously the gradient test...\n",
    "gsum = 0.\n",
    "for row in xrange(Xrat.shape[0]):\n",
    "    gsum += gradrll(theta, row, Xrat, Xfeat, buckets, I, J, K, R)\n",
    "print gsum\n",
    "print gradll(theta, Xrat, Xfeat, buckets, I, J, K, R)\n",
    "\n",
    "# do sgd approximation\n",
    "M = 100 # choose M samples\n",
    "gsum = 0.\n",
    "for row in np.random.randint(Xrat.shape[0], size=M):\n",
    "    # don't forget scaling!\n",
    "    gsum += 1. * Xrat.shape[0] / M * gradrll(theta, row, Xrat, Xfeat, buckets, I, J, K, R)\n",
    "print gsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02028665  0.11384461  0.05424302 ..., -0.01680089  0.05670319\n",
      "  0.03054118]\n",
      "-137313.916399\n",
      "[-0.01427396  0.11087967  0.05424302 ..., -0.01680089  0.05670319\n",
      "  0.03054118]\n",
      "-32406.2192898\n"
     ]
    }
   ],
   "source": [
    "# one epoch of sgd!\n",
    "\n",
    "theta0 = theta.copy()\n",
    "\n",
    "# combined learning_rate * scale_factor\n",
    "alpha = 0.05\n",
    "\n",
    "print theta0\n",
    "print loglikelihood(theta0, Xrat, Xfeat, buckets, I, J, K, R)\n",
    "\n",
    "# shuffle data here!\n",
    "for row in xrange(Xrat.shape[0]):\n",
    "    # update theta0 according to current row\n",
    "    theta0 += alpha * gradrll(theta0, row, Xrat, Xfeat, buckets, I, J, K, R)\n",
    "    \n",
    "print theta0\n",
    "print loglikelihood(theta0, Xrat, Xfeat, buckets, I, J, K, R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-9e14358ee8c3>, line 26)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-9e14358ee8c3>\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    def fit(self, X, y, ...):\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# # Overall Todos:\n",
    "# # add Documentation, code in MLib style\n",
    "\n",
    "# # This shall be designed for modelling ratings\n",
    "# # assume we are given n users i =1, ..., I\n",
    "# # that rated m items j= 1, ..., J\n",
    "# # Y_n ~ u_i^Tv_j + a_i + b_j + g + X_n * w\n",
    "# # u_i, v_j are K-dimensional latent variable vectors\n",
    "# # a_i, b_j, g are user/item/global wise biases (latent)\n",
    "# # X_n represents the n-th data row with L features\n",
    "# # w is the weight vector we want to train for\n",
    "# # Thus, in total our model trains the parameter vector\n",
    "# # theta = (u_1, ..., u_I, v_1, ..., v_J, a_1, ..., a_I, b_1, ..., b_J, g, w)\n",
    "# class CumulativeModel:\n",
    "    \n",
    "    \n",
    "#     def __init__(self, buckets = None, modelType = 'logistic', spark=False, numLatentFactors=0):\n",
    "#         # add here check for correct model types\n",
    "#         # logistic, probit, minev, maxev\n",
    "#         self.mtype = modelType\n",
    "#         self.useSpark = spark\n",
    "#         self.K = numLatentFactors\n",
    "#         self.buckets = buckets\n",
    "        \n",
    "#     # add here sgd parameters\n",
    "#     def fit(self, X, y, ...):\n",
    "#         # first set buckets if necessary\n",
    "#         if self.buckets is None:\n",
    "#             warning()\n",
    "        \n",
    "#     # make a prediction\n",
    "#     def predict(self, X, y, ...):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
